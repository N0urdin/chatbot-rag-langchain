# ğŸ§  Chatbot RAG avec LangChain & LLM

Ce projet met en place un chatbot intelligent capable de rÃ©pondre Ã  des questions spÃ©cifiques Ã  partir dâ€™un corpus documentaire, grÃ¢ce Ã  lâ€™architecture RAG (Retrieval-Augmented Generation).

## ğŸ“Œ Objectifs
- Utiliser des LLMs pour rÃ©pondre Ã  des questions mÃ©tier/documentation
- Mettre en place un moteur de recherche sÃ©mantique avec FAISS/Pinecone
- IntÃ©grer une interface utilisateur via Streamlit

## âš™ï¸ Technologies
- Python, LangChain, Streamlit
- ModÃ¨les LLM (Mixtral / OpenAI)
- Pinecone (ou FAISS) pour la base vectorielle

## ğŸ“ Structure
```
ğŸ“‚ chatbot-rag
â”œâ”€â”€ data/                   # Fichiers source (PDF, txt)
â”œâ”€â”€ app.py                  # Interface utilisateur (Streamlit)
â”œâ”€â”€ rag_pipeline.py         # Logique de rÃ©cupÃ©ration + gÃ©nÃ©ration
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## â–¶ï¸ Lancer le projet
```bash
pip install -r requirements.txt
streamlit run app.py
```

## ğŸ“š Inspirations
- [LangChain docs](https://docs.langchain.com)
- Tutoriels Credera Engineering, Mistral AI
